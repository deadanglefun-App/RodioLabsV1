#!/usr/bin/env python3
"""
Tests du consensus multi-nÅ“uds RODIO
Valide le comportement du consensus dans diffÃ©rents scÃ©narios
"""

import asyncio
import aiohttp
import json
import time
import logging
from typing import List, Dict, Any
from dataclasses import dataclass

@dataclass
class NodeInfo:
    """Informations d'un nÅ“ud RODIO"""
    node_id: str
    url: str
    status: str = "unknown"
    last_response_time: float = 0.0

class ConsensusTestSuite:
    """Suite de tests pour le consensus RODIO"""
    
    def __init__(self):
        self.nodes = [
            NodeInfo("GATEWAY_01", "http://localhost:8081"),
            NodeInfo("GATEWAY_02", "http://localhost:8082"),
            NodeInfo("GATEWAY_03", "http://localhost:8083"),
        ]
        
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
        self.test_results = []
    
    async def check_nodes_health(self) -> bool:
        """VÃ©rifie que tous les nÅ“uds sont opÃ©rationnels"""
        self.logger.info("ğŸ” VÃ©rification de la santÃ© des nÅ“uds...")
        
        healthy_nodes = 0
        
        async with aiohttp.ClientSession() as session:
            for node in self.nodes:
                try:
                    start_time = time.time()
                    async with session.get(f"{node.url}/health", timeout=5) as response:
                        if response.status == 200:
                            data = await response.json()
                            node.status = data.get('status', 'unknown')
                            node.last_response_time = time.time() - start_time
                            
                            if node.status == 'healthy':
                                healthy_nodes += 1
                                self.logger.info(f"âœ… {node.node_id}: {node.status} ({node.last_response_time:.3f}s)")
                            else:
                                self.logger.warning(f"âš ï¸ {node.node_id}: {node.status}")
                        else:
                            node.status = f"http_{response.status}"
                            self.logger.error(f"âŒ {node.node_id}: HTTP {response.status}")
                            
                except Exception as e:
                    node.status = "unreachable"
                    self.logger.error(f"âŒ {node.node_id}: {str(e)}")
        
        success = healthy_nodes >= 3
        self.logger.info(f"ğŸ“Š NÅ“uds sains: {healthy_nodes}/{len(self.nodes)}")
        return success
    
    async def test_normal_consensus(self) -> bool:
        """Test du consensus avec des valeurs cohÃ©rentes"""
        self.logger.info("ğŸ§ª Test: Consensus normal avec valeurs cohÃ©rentes")
        
        # Simulation de donnÃ©es cohÃ©rentes
        test_data = {
            "sensor_id": "temp_test_01",
            "readings": [
                {"node_id": "GATEWAY_01", "value": 23.1, "timestamp": int(time.time())},
                {"node_id": "GATEWAY_02", "value": 23.3, "timestamp": int(time.time())},
                {"node_id": "GATEWAY_03", "value": 23.2, "timestamp": int(time.time())},
            ]
        }
        
        try:
            # Envoi des donnÃ©es Ã  chaque nÅ“ud
            async with aiohttp.ClientSession() as session:
                tasks = []
                for i, node in enumerate(self.nodes):
                    reading = test_data["readings"][i]
                    task = self._send_sensor_data(session, node, reading)
                    tasks.append(task)
                
                results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # VÃ©rification des rÃ©sultats
            successful_submissions = sum(1 for r in results if r is True)
            
            if successful_submissions >= 3:
                self.logger.info("âœ… Consensus normal: SUCCÃˆS")
                return True
            else:
                self.logger.error(f"âŒ Consensus normal: Ã‰CHEC ({successful_submissions}/3)")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ Erreur test consensus normal: {e}")
            return False
    
    async def test_outlier_handling(self) -> bool:
        """Test de gestion des outliers"""
        self.logger.info("ğŸ§ª Test: Gestion des outliers")
        
        # Simulation avec un outlier
        test_data = {
            "sensor_id": "temp_test_02",
            "readings": [
                {"node_id": "GATEWAY_01", "value": 23.1, "timestamp": int(time.time())},
                {"node_id": "GATEWAY_02", "value": 50.0, "timestamp": int(time.time())},  # Outlier
                {"node_id": "GATEWAY_03", "value": 23.2, "timestamp": int(time.time())},
            ]
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                tasks = []
                for i, node in enumerate(self.nodes):
                    reading = test_data["readings"][i]
                    task = self._send_sensor_data(session, node, reading)
                    tasks.append(task)
                
                results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # Le consensus devrait filtrer l'outlier
            successful_submissions = sum(1 for r in results if r is True)
            
            if successful_submissions >= 2:  # Au moins 2 nÅ“uds d'accord
                self.logger.info("âœ… Gestion outliers: SUCCÃˆS")
                return True
            else:
                self.logger.error("âŒ Gestion outliers: Ã‰CHEC")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ Erreur test outliers: {e}")
            return False
    
    async def test_node_failure_resilience(self) -> bool:
        """Test de rÃ©silience Ã  la panne d'un nÅ“ud"""
        self.logger.info("ğŸ§ª Test: RÃ©silience Ã  la panne d'un nÅ“ud")
        
        # Test avec seulement 2 nÅ“uds (simulation de panne du 3Ã¨me)
        active_nodes = self.nodes[:2]
        
        test_data = {
            "sensor_id": "temp_test_03",
            "readings": [
                {"node_id": "GATEWAY_01", "value": 23.1, "timestamp": int(time.time())},
                {"node_id": "GATEWAY_02", "value": 23.3, "timestamp": int(time.time())},
            ]
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                tasks = []
                for i, node in enumerate(active_nodes):
                    reading = test_data["readings"][i]
                    task = self._send_sensor_data(session, node, reading)
                    tasks.append(task)
                
                results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # Avec 2 nÅ“uds, le consensus devrait Ã©chouer (minimum 3 requis)
            successful_submissions = sum(1 for r in results if r is True)
            
            if successful_submissions < 3:
                self.logger.info("âœ… RÃ©silience panne: SUCCÃˆS (consensus refusÃ© avec <3 nÅ“uds)")
                return True
            else:
                self.logger.error("âŒ RÃ©silience panne: Ã‰CHEC (consensus acceptÃ© avec <3 nÅ“uds)")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ Erreur test rÃ©silience: {e}")
            return False
    
    async def test_consensus_timing(self) -> bool:
        """Test des performances temporelles du consensus"""
        self.logger.info("ğŸ§ª Test: Performance temporelle du consensus")
        
        start_time = time.time()
        
        test_data = {
            "sensor_id": "temp_test_04",
            "readings": [
                {"node_id": "GATEWAY_01", "value": 23.1, "timestamp": int(time.time())},
                {"node_id": "GATEWAY_02", "value": 23.2, "timestamp": int(time.time())},
                {"node_id": "GATEWAY_03", "value": 23.0, "timestamp": int(time.time())},
            ]
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                tasks = []
                for i, node in enumerate(self.nodes):
                    reading = test_data["readings"][i]
                    task = self._send_sensor_data(session, node, reading)
                    tasks.append(task)
                
                results = await asyncio.gather(*tasks, return_exceptions=True)
            
            consensus_time = time.time() - start_time
            
            # Le consensus devrait prendre moins de 5 secondes
            if consensus_time < 5.0:
                self.logger.info(f"âœ… Performance consensus: SUCCÃˆS ({consensus_time:.3f}s)")
                return True
            else:
                self.logger.warning(f"âš ï¸ Performance consensus: LENT ({consensus_time:.3f}s)")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ Erreur test performance: {e}")
            return False
    
    async def _send_sensor_data(self, session: aiohttp.ClientSession, node: NodeInfo, reading: Dict) -> bool:
        """Envoie des donnÃ©es de capteur Ã  un nÅ“ud"""
        try:
            async with session.post(
                f"{node.url}/api/sensor-data",
                json=reading,
                timeout=3
            ) as response:
                return response.status == 200
        except Exception as e:
            self.logger.debug(f"Erreur envoi donnÃ©es Ã  {node.node_id}: {e}")
            return False
    
    async def get_consensus_metrics(self) -> Dict[str, Any]:
        """RÃ©cupÃ¨re les mÃ©triques de consensus de tous les nÅ“uds"""
        metrics = {}
        
        async with aiohttp.ClientSession() as session:
            for node in self.nodes:
                try:
                    async with session.get(f"{node.url}/metrics", timeout=3) as response:
                        if response.status == 200:
                            text = await response.text()
                            metrics[node.node_id] = self._parse_prometheus_metrics(text)
                except Exception as e:
                    self.logger.debug(f"Erreur mÃ©triques {node.node_id}: {e}")
        
        return metrics
    
    def _parse_prometheus_metrics(self, metrics_text: str) -> Dict[str, float]:
        """Parse simple des mÃ©triques Prometheus"""
        metrics = {}
        for line in metrics_text.split('\n'):
            if line.startswith('rodio_consensus_success_rate'):
                try:
                    value = float(line.split()[-1])
                    metrics['consensus_success_rate'] = value
                except:
                    pass
            elif line.startswith('rodio_sensor_readings_total'):
                try:
                    value = float(line.split()[-1])
                    metrics['sensor_readings_total'] = value
                except:
                    pass
        return metrics
    
    async def run_full_test_suite(self) -> Dict[str, Any]:
        """ExÃ©cute la suite complÃ¨te de tests"""
        self.logger.info("ğŸš€ DÃ©marrage de la suite de tests consensus RODIO")
        self.logger.info("=" * 60)
        
        results = {
            "timestamp": int(time.time()),
            "total_tests": 0,
            "passed_tests": 0,
            "failed_tests": 0,
            "test_details": []
        }
        
        # Liste des tests Ã  exÃ©cuter
        tests = [
            ("health_check", self.check_nodes_health),
            ("normal_consensus", self.test_normal_consensus),
            ("outlier_handling", self.test_outlier_handling),
            ("node_failure_resilience", self.test_node_failure_resilience),
            ("consensus_timing", self.test_consensus_timing),
        ]
        
        for test_name, test_func in tests:
            self.logger.info(f"\nğŸ“‹ ExÃ©cution: {test_name}")
            
            try:
                start_time = time.time()
                success = await test_func()
                duration = time.time() - start_time
                
                results["total_tests"] += 1
                if success:
                    results["passed_tests"] += 1
                else:
                    results["failed_tests"] += 1
                
                results["test_details"].append({
                    "name": test_name,
                    "success": success,
                    "duration": round(duration, 3)
                })
                
            except Exception as e:
                self.logger.error(f"âŒ Erreur critique dans {test_name}: {e}")
                results["total_tests"] += 1
                results["failed_tests"] += 1
                results["test_details"].append({
                    "name": test_name,
                    "success": False,
                    "error": str(e)
                })
        
        # RÃ©cupÃ©ration des mÃ©triques finales
        try:
            final_metrics = await self.get_consensus_metrics()
            results["final_metrics"] = final_metrics
        except Exception as e:
            self.logger.warning(f"Impossible de rÃ©cupÃ©rer les mÃ©triques finales: {e}")
        
        # Rapport final
        self.logger.info("\n" + "=" * 60)
        self.logger.info("ğŸ“Š RAPPORT FINAL DES TESTS")
        self.logger.info("=" * 60)
        self.logger.info(f"Tests exÃ©cutÃ©s: {results['total_tests']}")
        self.logger.info(f"Tests rÃ©ussis: {results['passed_tests']}")
        self.logger.info(f"Tests Ã©chouÃ©s: {results['failed_tests']}")
        
        success_rate = (results['passed_tests'] / results['total_tests']) * 100 if results['total_tests'] > 0 else 0
        self.logger.info(f"Taux de rÃ©ussite: {success_rate:.1f}%")
        
        if success_rate >= 80:
            self.logger.info("ğŸ‰ CONSENSUS RODIO: VALIDATION RÃ‰USSIE!")
        else:
            self.logger.error("âŒ CONSENSUS RODIO: PROBLÃˆMES DÃ‰TECTÃ‰S")
        
        return results

async def main():
    """Point d'entrÃ©e principal"""
    test_suite = ConsensusTestSuite()
    
    try:
        results = await test_suite.run_full_test_suite()
        
        # Sauvegarde des rÃ©sultats
        with open(f"consensus_test_results_{int(time.time())}.json", "w") as f:
            json.dump(results, f, indent=2)
        
        return results["passed_tests"] == results["total_tests"]
        
    except KeyboardInterrupt:
        print("\nğŸ›‘ Tests interrompus par l'utilisateur")
        return False
    except Exception as e:
        print(f"âŒ Erreur critique: {e}")
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    exit(0 if success else 1)